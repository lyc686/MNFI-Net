                 from  n    params  module                                  arguments
  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]
  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]
  2                -1  2     23208  models.common.C3Ghost                   [96, 96, 2]
  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]
  4                -1  4    101280  models.common.C3Ghost                   [192, 192, 4]
  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]
  6                -1  6    432096  models.common.C3Ghost                   [384, 384, 6]
  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]
  8                -1  2   1346880  models.common.C3Ghost                   [768, 768, 2]
  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]
 10                -1  2   1346880  models.common.C3Ghost                   [768, 768, 2, False]
 11                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]
 12                 6  2    341664  models.common.C3Ghost                   [384, 384, 2, False]
 13                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]
 14          [-1, 11]  1         0  models.common.Concat                    [1]
 15                -1  1    591360  models.common.Conv                      [768, 768, 1, 1]
 16                -1  1         0  models.common.Res2Ghost                 [768, 768, False]
 17                -1  1    591360  models.common.Conv                      [768, 768, 1, 1]
 18          [-1, 10]  1         0  models.common.Concat                    [1]
 19                -1  2   1936704  models.common.C3Ghost                   [1536, 768, 2, False]
 20                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]
 21                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]
 22                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 23                 4  2     87888  models.common.C3Ghost                   [192, 192, 2, False]
 24                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]
 25                 6  2    124752  models.common.C3Ghost                   [384, 192, 2, False]
 26      [-1, 22, 24]  1         0  models.common.Concat                    [1]
 27                -1  1    221952  models.common.Conv                      [576, 384, 1, 1]
 28                -1  1         0  models.common.Res2Ghost                 [384, 384, False]
 29                -1  1    148224  models.common.Conv                      [384, 384, 1, 1]
 30           [-1, 6]  1         0  models.common.Concat                    [1]
 31                -1  2   1346880  models.common.C3Ghost                   [768, 768, 2, False]
 32                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]
 33                -1  1     37056  models.common.Conv                      [384, 96, 1, 1]
 34                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 35                 2  2     23208  models.common.C3Ghost                   [96, 96, 2, False]
 36                -1  1     83136  models.common.Conv                      [96, 96, 3, 2]
 37                 4  2     32424  models.common.C3Ghost                   [192, 96, 2, False]
 38      [-1, 34, 36]  1         0  models.common.Concat                    [1]
 39                -1  1     55680  models.common.Conv                      [288, 192, 1, 1]
 40                -1  1         0  models.common.Res2Ghost                 [192, 192, False]
 41                -1  1     37248  models.common.Conv                      [192, 192, 1, 1]
 42           [-1, 4]  1         0  models.common.Concat                    [1]
 43                18  1    159748  models.common.GAM_Attention             [1536, 1536]
 44                30  1     79876  models.common.GAM_Attention             [768, 768]
 45                42  1     39940  models.common.GAM_Attention             [384, 384]
 46                43  2   5347968  models.common.C3Ghost                   [1536, 1536, 2, False]
 47                44  2   1346880  models.common.C3Ghost                   [768, 768, 2, False]
 48                45  2    341664  models.common.C3Ghost                   [384, 384, 2, False]
 49      [48, 47, 46]  1    104949  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [384, 768, 1536]]
test_2 summary: 1005 layers, 23962233 parameters, 23962233 gradients, 49.5 GFLOPs
[34m[1mAMP: [39m[22mchecks passed ‚úÖ
[34m[1moptimizer:[39m[22m SGD(lr=0.01) with parameter groups 216 weight(decay=0.0), 225 weight(decay=0.0005), 231 bias
[34m[1mtrain: [39m[22mScanning /home/zhangfeng/liuyuchen/yolov5-res2ghost/dataset/new_gf2173/labels/train.cache... 1565 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
[34m[1mval: [39m[22mScanning /home/zhangfeng/liuyuchen/yolov5-res2ghost/dataset/new_gf2173/labels/val.cache... 173 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/1
[34m[1mAutoAnchor: [39m[22m2.98 anchors/target, 0.838 Best Possible Recall (BPR). Anchors are a poor fit to dataset ‚ö†Ô∏è, attempting to improve...
[34m[1mAutoAnchor: [39m[22mRunning kmeans for 9 anchors on 3095 points...
[34m[1mAutoAnchor: [39m[22mEvolving anchors with Genetic Algorithm: fitness = 0.8007: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:02<00:00, 487.82it/s]
[34m[1mAutoAnchor: [39m[22mthr=0.25: 1.0000 best possible recall, 2.96 anchors past thr
[34m[1mAutoAnchor: [39m[22mn=9, img_size=640, metric_all=0.228/0.801-mean/best, past_thr=0.538-mean: 11,50, 12,85, 41,35, 26,135, 122,49, 601,15, 19,637, 250,199, 591,597
[34m[1mAutoAnchor: [39m[22mDone ‚úÖ (optional: update model *.yaml to use these anchors in the future)
Plotting labels to runs/train/exp9/labels.jpg...
Image sizes 640 train, 640 val
Using 8 dataloader workers
Logging results to [1mruns/train/exp9
Starting training for 500 epochs...
      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
  0%|          | 0/98 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "train.py", line 640, in <module>
    main(opt)
  File "train.py", line 529, in main
    train(opt.hyp, opt, device, callbacks)
  File "train.py", line 318, in train
    scaler.scale(loss).backward()
  File "/home/zhangfeng/anaconda3/envs/lyc_torch38/lib/python3.8/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/zhangfeng/anaconda3/envs/lyc_torch38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution